import csv, re, time
from datetime import datetime, timedelta
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# ---------------- à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹à¸›à¸¥à¸‡à¸§à¸±à¸™/à¹€à¸§à¸¥à¸² ----------------
def parse_thai_datetime(text):
    text = text.replace("\xa0", " ").strip()
    m = re.search(r"(\d+)\s*(à¸™à¸²à¸—à¸µ|à¸Šà¸¡\.|à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡|à¸§à¸±à¸™|à¸§à¸´à¸™à¸²à¸—à¸µ)", text)
    if m:
        amount = int(m[1])
        unit_map = {"à¸™à¸²à¸—à¸µ": "minutes", "à¸Šà¸¡.": "hours", "à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡": "hours",
                    "à¸§à¸±à¸™": "days", "à¸§à¸´à¸™à¸²à¸—à¸µ": "seconds"}
        return datetime.now() - timedelta(**{unit_map[m[2]]: amount})
    return None

# ---------------- à¸„à¹ˆà¸²à¸„à¸‡à¸—à¸µà¹ˆ ----------------
TAG_URL = "https://pantip.com/tag/à¸«à¸¸à¹‰à¸™"
LIMIT_ROWS = 10000
WAIT = 1.5

# ---------------- Selenium ----------------
opt = Options()
opt.add_experimental_option('excludeSwitches', ['enable-logging'])
opt.add_argument('--log-level=3')
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opt)

# ---------------- à¹€à¸•à¸£à¸µà¸¢à¸¡à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ ----------------
seen_texts = set()
saved_rows = 0
csvfile = open("pantip_data.csv", "w", newline="", encoding="utf-8")
writer = csv.writer(csvfile)
writer.writerow(["type", "data", "date"])

def save(type_, text, date_str):
    global saved_rows
    text = text.strip()
    if not text or text in seen_texts or saved_rows >= LIMIT_ROWS:
        return
    writer.writerow([type_, text, date_str])
    seen_texts.add(text)
    saved_rows += 1

# ---------------- MAIN ----------------
try:
    driver.get(TAG_URL)
    time.sleep(3)

    SCROLL_TIMES = 30
    SCROLL_DELAY = 2.5

    for i in range(SCROLL_TIMES):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight)")
        time.sleep(SCROLL_DELAY)
    soup = BeautifulSoup(driver.page_source, "html.parser")
    
    
    block = soup.select_one("#pt-topic-left > div:nth-child(2)")
    if not block:
        raise Exception("âŒ à¹„à¸¡à¹ˆà¹€à¸ˆà¸­ block à¸«à¸¥à¸±à¸à¸à¸£à¸°à¸—à¸¹à¹‰")

    items = block.select("ul > li")
    
    print(f"ğŸ“Œ à¸à¸šà¸à¸£à¸°à¸—à¸¹à¹‰ {len(items)} à¸£à¸²à¸¢à¸à¸²à¸£à¹ƒà¸™ block")

    for idx, li in enumerate(items, start=1):
        if saved_rows >= LIMIT_ROWS:
            break

        title_tag = li.select_one("div.pt-list-item__title")
        time_tag = li.select_one("div.pt-list-item__info > span")
        link_tag = li.select_one("a[href*='/topic']")
        if not (title_tag and time_tag and link_tag):
            continue

        title_text = title_tag.get_text(" ", strip=True)
        time_obj = parse_thai_datetime(time_tag.text)
        url = "https://pantip.com" + link_tag["href"] if not link_tag["href"].startswith("http") else link_tag["href"]
        topic_id_match = re.findall(r'/topic/(\d+)', url)
        topic_id = topic_id_match[0] if topic_id_match else None
        if not topic_id:
            continue

        driver.get(url)
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, f"#topic-{topic_id}"))
            )
        except:
            print(f"âš ï¸ timeout: à¹„à¸¡à¹ˆà¹€à¸ˆà¸­à¹‚à¸à¸ªà¸•à¹Œà¹ƒà¸™ {url}")
            continue

        psoup = BeautifulSoup(driver.page_source, "html.parser")

        # --- à¹à¸¢à¸ topic à¹à¸¥à¸° post à¸­à¸­à¸à¸ˆà¸²à¸à¸à¸±à¸™ ---

        # âŠ à¹€à¸à¹‡à¸š topic (à¸«à¸±à¸§à¸‚à¹‰à¸­à¸à¸£à¸°à¸—à¸¹à¹‰)
        save("topic", title_text, time_obj.strftime("%Y-%m-%d %H:%M:%S") if time_obj else "N/A")

        # â‹ à¸à¸¢à¸²à¸¢à¸²à¸¡à¸«à¸² post (à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹‚à¸à¸ªà¸•à¹Œà¸«à¸¥à¸±à¸)
        post_sel = f"#topic-{topic_id} > div > div:nth-child(4) > div.display-post-story-wrapper > div"
        post_node = psoup.select_one(post_sel)
        post_txt = post_node.get_text(" ", strip=True) if post_node else ""

        # âŒ à¸–à¹‰à¸²à¸¡à¸µà¹€à¸™à¸·à¹‰à¸­à¸«à¸² à¸à¹‡à¹€à¸à¹‡à¸šà¹à¸¢à¸à¹€à¸›à¹‡à¸™ post
        if post_txt:
            save("post", post_txt, time_obj.strftime("%Y-%m-%d %H:%M:%S") if time_obj else "N/A")
        else:
            print(f"âš ï¸ à¹„à¸¡à¹ˆà¹€à¸ˆà¸­à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹‚à¸à¸ªà¸•à¹Œà¹ƒà¸™: {url}")


        # --- à¸„à¸­à¸¡à¹€à¸¡à¸™à¸•à¹Œ (à¸¥à¸­à¸‡à¸«à¸¥à¸²à¸¢ layout) ---
        comments = psoup.select("#comments-jsrender div[id^='comment-']")
        for c in comments:
            if saved_rows >= LIMIT_ROWS: break
            msg = c.select_one("div.display-post-story-wrapper.comment-wrapper") \
               or c.select_one("div[data-role='comment-body']") \
               or c.select_one("div.post-message")
            time_ = c.select_one("span[data-role='timestamp']") \
                 or c.select_one("div.display-post-avatar > div > span")
            c_text = msg.get_text(" ", strip=True) if msg else ""
            c_date = parse_thai_datetime(time_.text) if time_ else None
            save("comment", c_text, c_date.strftime("%Y-%m-%d %H:%M:%S") if c_date else "N/A")

        print(f"âœ… [{idx}/{len(items)}] {title_text[:60]} â€” saved: {saved_rows}/10000")

finally:
    csvfile.close()
    driver.quit()
    print(f"\nğŸ‰ à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§! à¸šà¸±à¸™à¸—à¸¶à¸ {saved_rows} à¹à¸–à¸§ â†’ pantip_data.csv")
