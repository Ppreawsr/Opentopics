import csv
import re
import time
from datetime import datetime, timedelta

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# ------------------------------
#  ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô parse ‡∏ß‡∏±‡∏ô-‡πÄ‡∏ß‡∏•‡∏≤
# ------------------------------
def parse_relative_time(text: str):
    text = text.strip()
    unit_map = {
        "‡∏ô‡∏≤‡∏ó‡∏µ": "minutes", "‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß": "minutes",
        "‡∏ä‡∏°.": "hours", "‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á": "hours",
        "‡∏ß‡∏±‡∏ô": "days", "‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ": "seconds",
        "‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß": "seconds"
    }
    pattern = r"(\d+)\s*(‡∏ô‡∏≤‡∏ó‡∏µ|‡∏ä‡∏°\.|‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á|‡∏ß‡∏±‡∏ô|‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)(‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß|‡∏Å‡πà‡∏≠‡∏ô)?"
    m = re.search(pattern, text)
    if not m:
        return None

    amount_str = m.group(1)
    unit_thai = m.group(2)
    try:
        amount = int(amount_str)
        if amount > 999999:
            return None
    except:
        return None

    now = datetime.now()
    if unit_thai not in unit_map:
        return None
    time_unit = unit_map[unit_thai]

    if time_unit == "minutes":
        dt = now - timedelta(minutes=amount)
    elif time_unit == "hours":
        dt = now - timedelta(hours=amount)
    elif time_unit == "days":
        dt = now - timedelta(days=amount)
    elif time_unit == "seconds":
        dt = now - timedelta(seconds=amount)
    else:
        return None
    return dt

def parse_full_thai_datetime(text: str):
    text = text.strip()
    thai_months = {
        "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°": 1, "‡∏°.‡∏Ñ.": 1,
        "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå": 2, "‡∏Å.‡∏û.": 2,
        "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°": 3, "‡∏°‡∏µ.‡∏Ñ.": 3,
        "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô": 4, "‡πÄ‡∏°.‡∏¢.": 4,
        "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°": 5, "‡∏û.‡∏Ñ.": 5,
        "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô": 6, "‡∏°‡∏¥.‡∏¢.": 6,
        "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°": 7, "‡∏Å.‡∏Ñ.": 7,
        "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°": 8, "‡∏™.‡∏Ñ.": 8,
        "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô": 9, "‡∏Å.‡∏¢.": 9,
        "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°": 10, "‡∏ï.‡∏Ñ.": 10,
        "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô": 11, "‡∏û.‡∏¢.": 11,
        "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°": 12, "‡∏ò.‡∏Ñ.": 12
    }
    pattern = r"(\d{1,2})\s+([‡∏Å-‡∏Æ.]+)\s+(\d{4})\s*(?:‡πÄ‡∏ß‡∏•‡∏≤\s*(\d{1,2}):(\d{1,2})\s*‡∏ô\.)?"
    m = re.search(pattern, text)
    if not m:
        return None

    day_str = m.group(1)
    month_thai = m.group(2)
    year_thai_str = m.group(3)
    hour_str = m.group(4)
    minute_str = m.group(5)

    if not hour_str:
        hour_str = "0"
    if not minute_str:
        minute_str = "0"

    try:
        day = int(day_str)
        year_thai = int(year_thai_str)
        hour = int(hour_str)
        minute = int(minute_str)
    except:
        return None

    if month_thai not in thai_months:
        return None

    month = thai_months[month_thai]
    year = year_thai - 543  # ‡∏û.‡∏®. -> ‡∏Ñ.‡∏®.

    try:
        dt = datetime(year, month, day, hour, minute)
    except:
        return None
    return dt

def parse_thai_datetime(text: str):
    dt = parse_relative_time(text)
    if dt:
        return dt
    dt = parse_full_thai_datetime(text)
    if dt:
        return dt
    return None

def format_datetime(dt: datetime):
    if not dt:
        return "N/A"
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def is_within_days(dt, max_days=5):
    if not dt:
        return False
    now = datetime.now()
    return (now - dt).days < max_days

# ---------------------------
# ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°
# ---------------------------
MAX_DAYS = 5
SCROLL_TIMES = 100  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô
SCROLL_STEP_PX = 300
WAIT_SCROLL = 1.5

# ‡∏õ‡∏¥‡∏î log ‡πÄ‡∏Å‡∏∞‡∏Å‡∏∞
chrome_options = Options()
chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
chrome_options.add_argument('--log-level=3')

service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=chrome_options)

try:
    driver.get("https://pantip.com/tag/‡∏´‡∏∏‡πâ‡∏ô")
    time.sleep(3)

    print(f"üîΩ Scroll by {SCROLL_STEP_PX}px, for {SCROLL_TIMES} times ...")
    for i in range(SCROLL_TIMES):
        driver.execute_script(f"window.scrollBy(0, {SCROLL_STEP_PX});")
        time.sleep(WAIT_SCROLL)

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏û‡∏™‡∏ï‡πå
    soup = BeautifulSoup(driver.page_source, "html.parser")
    container = soup.select_one("#__next > div > div > div > div.container > div:nth-child(6) > div.col-lg-8")
    all_post_links = []
    if container:
        posts = container.select("li.pt-list-item")
        print(f"üîé ‡∏û‡∏ö {len(posts)} posts ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô)")
        for p in posts:
            link_tag = p.select_one("div.pt-list-item__title a")
            date_tag = p.select_one("div.pt-list-item__info")
            if link_tag and date_tag:
                href = link_tag.get("href")
                date_str = date_tag.get_text(strip=True)
                dt_obj = parse_thai_datetime(date_str)
                if dt_obj and is_within_days(dt_obj, MAX_DAYS):
                    full_url = href if href.startswith("http") else ("https://pantip.com" + href)
                    all_post_links.append(full_url)
    else:
        print("‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ container ‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤")

    print(f"‚úÖ ‡πÑ‡∏î‡πâ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏†‡∏≤‡∏¢‡πÉ‡∏ô {MAX_DAYS} ‡∏ß‡∏±‡∏ô: {len(all_post_links)} ‡∏•‡∏¥‡∏á‡∏Å‡πå")

    if not all_post_links:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£")
    else:
        with open("pantip_data_5days.csv", "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["post_id", "type", "day", "datetime", "title", "content", "author"])

            for i, link in enumerate(all_post_links, start=1):
                driver.get(link)
                time.sleep(2)
                post_soup = BeautifulSoup(driver.page_source, "html.parser")

                title_tag = post_soup.select_one("title")
                title = title_tag.get_text(strip=True) if title_tag else "N/A"

                post_dt_div = post_soup.select_one("div.display-post-status-leftside")
                dt_str = post_dt_div.get_text(strip=True) if post_dt_div else ""
                post_dt_obj = parse_thai_datetime(dt_str)
                day_str = dt_obj.strftime('%Y-%m-%d') if dt_obj else "N/A"
                final_dt_str = format_datetime(dt_obj)

                author_tag = post_soup.select_one(".display-post-name")
                author = author_tag.get_text(strip=True) if author_tag else "Unknown"

                writer.writerow([link, "post", day_str, final_dt_str, title, "‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏´‡∏•‡∏±‡∏Å", author])

        print("\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå 'pantip_data_5days.csv'")

finally:
    driver.quit()
    print("‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
