import csv
import re
import time
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

def parse_relative_time(text: str):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡πà‡∏ô "20 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß", "3 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß", "1 ‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô" -> datetime.now() - timedelta(...)
    ‡∏ñ‡πâ‡∏≤ parse ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ -> return None
    """
    text = text.strip()
    unit_map = {
        "‡∏ô‡∏≤‡∏ó‡∏µ": "minutes",
        "‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á": "hours",
        "‡∏ß‡∏±‡∏ô": "days"
    }
    pattern = r"(\d+)\s*(‡∏ô‡∏≤‡∏ó‡∏µ|‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á|‡∏ß‡∏±‡∏ô)(‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß|‡∏Å‡πà‡∏≠‡∏ô)?"
    m = re.search(pattern, text)
    if not m:
        return None
    number_str = m.group(1)
    unit_thai = m.group(2)

    try:
        amount = int(number_str)
    except:
        return None

    now = datetime.now()

    if unit_thai not in unit_map:
        return None

    if unit_map[unit_thai] == "minutes":
        real_time = now - timedelta(minutes=amount)
    elif unit_map[unit_thai] == "hours":
        real_time = now - timedelta(hours=amount)
    elif unit_map[unit_thai] == "days":
        real_time = now - timedelta(days=amount)
    else:
        return None

    return real_time


def format_datetime(dt: datetime):
    return dt.strftime("%Y-%m-%d %H:%M:%S") if dt else "N/A"


# -----------------------------------------------------------------------------
# ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:
# 1) ‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå (type=post) + ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå (type=comment) ‡∏Ñ‡∏ô‡∏•‡∏∞ row
# 2) ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏±‡∏ô (pagination)
# 3) ‡πÉ‡∏™‡πà emoji
# 4) parse ‡πÄ‡∏ß‡∏•‡∏≤‡∏à‡∏≤‡∏Å "xx ‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß"
# 5) ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ str-capabilities ‡∏î‡πâ‡∏ß‡∏¢ Service
# -----------------------------------------------------------------------------

MAX_POSTS = 20  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î

# ‡∏™‡∏£‡πâ‡∏≤‡∏á WebDriver ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Service object
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)

try:
    page_url = "https://pantip.com/tag/‡∏´‡∏∏‡πâ‡∏ô"
    total_scraped = 0
    all_posts = []

    while True:
        print(f"üîé ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏Ç‡πâ‡∏≤: {page_url}")
        driver.get(page_url)
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, "html.parser")

        container = soup.select_one("#__next > div > div > div > div.container > div:nth-child(6) > div.col-lg-8")
        if not container:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö container ‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ, ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
            break

        posts = container.select("li.pt-list-item")
        if not posts:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÉ‡∏î ‡πÜ ‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ, ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
            break

        for post in posts:
            if total_scraped >= MAX_POSTS:
                break

            title_tag = post.select_one("div.pt-list-item__title a")
            if not title_tag:
                continue

            title = title_tag.get_text(strip=True)
            link = title_tag.get("href")

            # ‡∏•‡∏≠‡∏á parse ‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ ‡∏à‡∏≤‡∏Å info span
            info_span = post.select_one("div.pt-list-item__info span")
            date_str = info_span.get("title") if info_span and info_span.has_attr("title") else ""
            dt_obj = parse_relative_time(date_str)

            all_posts.append((title, link, dt_obj))
            total_scraped += 1

        if total_scraped >= MAX_POSTS:
            break

        # ‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        next_btn = soup.select_one("a.pagination-next")
        if not next_btn:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß, ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
            break

        next_href = next_btn.get("href")
        if not next_href.startswith("http"):
            next_href = "https://pantip.com" + next_href

        page_url = next_href

    print(f"‚ú® ‡∏£‡∏ß‡∏°‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏î‡πâ {len(all_posts)} ‡πÇ‡∏û‡∏™‡∏ï‡πå, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î...")

    # ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå CSV
    with open("pantip_data_hun.csv", "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: [type, title, datetime, content]
        writer.writerow(["type", "title", "datetime", "content"])

        # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏û‡∏™‡∏ï‡πå + ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå
        for i, (title, link, dt_obj) in enumerate(all_posts, start=1):
            print(f"\n‚öôÔ∏è [{i}/{len(all_posts)}] ‡πÇ‡∏û‡∏™‡∏ï‡πå: {title}")
            driver.get(link)
            time.sleep(3)

            post_soup = BeautifulSoup(driver.page_source, "html.parser")

            # (1) parse ‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á
            post_dt_div = post_soup.select_one("div.display-post-status-leftside")
            dt_str2 = post_dt_div.get_text(strip=True) if post_dt_div else ""
            post_dt_obj = parse_relative_time(dt_str2)
            final_dt_str = format_datetime(post_dt_obj)

            # (2) ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÇ‡∏û‡∏™‡∏ï‡πå
            post_content_div = post_soup.select_one("div.display-post-story")
            post_content = post_content_div.get_text(separator=" ", strip=True) if post_content_div else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÇ‡∏û‡∏™‡∏ï‡πå"

            #  ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏û‡∏™‡∏ï‡πå (type=post)
            writer.writerow(["post", title, final_dt_str, post_content])

            # (3) ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå
            comments = post_soup.select("div.display-post-wrapper.section-comment")
            print(f"üí¨ ‡∏û‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå {len(comments)} ‡∏≠‡∏±‡∏ô")
            for c in comments:
                # parse ‡πÄ‡∏ß‡∏•‡∏≤ comment
                c_dt_div = c.select_one("div.display-post-status-leftside")
                c_dt_str = c_dt_div.get_text(strip=True) if c_dt_div else ""
                c_dt_obj = parse_relative_time(c_dt_str)
                c_dt_final = format_datetime(c_dt_obj)

                # ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå
                c_content_div = c.select_one("div.display-post-story-wrapper.comment-wrapper div.display-post-story")
                c_content = c_content_div.get_text(separator=" ", strip=True) if c_content_div else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå"

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (type=comment)
                writer.writerow(["comment", title, c_dt_final, c_content])

    print("\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå 'pantip_data_hun.csv'")

finally:
    driver.quit()
    print("üö™ ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
