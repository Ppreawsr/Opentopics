import csv
import re
import time
from datetime import datetime, timedelta

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# ------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô parse_full_thai_datetime (‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°)
# ------------------------------
def parse_full_thai_datetime(text: str):
    text = text.replace("\xa0"," ").replace("\r","").strip()

    def normalize_month(m_str: str):
        alias = {
            "‡πÄ‡∏°‡∏¢": "‡πÄ‡∏°.‡∏¢.",
            "‡πÄ‡∏°‡∏¢.": "‡πÄ‡∏°.‡∏¢.",
            "‡πÄ‡∏°.‡∏¢": "‡πÄ‡∏°.‡∏¢.",
            "‡πÄ‡∏°.‡∏¢.": "‡πÄ‡∏°.‡∏¢."
        }
        return alias.get(m_str, m_str)

    thai_months = {
        "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°": 1, "‡∏°.‡∏Ñ.": 1,
        "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå": 2, "‡∏Å.‡∏û.": 2,
        "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°": 3, "‡∏°‡∏µ.‡∏Ñ.": 3,
        "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô": 4, "‡πÄ‡∏°.‡∏¢.": 4,
        "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°": 5, "‡∏û.‡∏Ñ.": 5,
        "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô": 6, "‡∏°‡∏¥.‡∏¢.": 6,
        "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°": 7, "‡∏Å.‡∏Ñ.": 7,
        "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°": 8, "‡∏™.‡∏Ñ.": 8,
        "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô": 9, "‡∏Å.‡∏¢.": 9,
        "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°": 10, "‡∏ï.‡∏Ñ.": 10,
        "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô": 11, "‡∏û.‡∏¢.": 11,
        "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°": 12, "‡∏ò.‡∏Ñ.": 12
    }

    pattern_full = r"(\d{1,2})\s+([‡∏Å-‡∏Æ.]+)\s+(\d{2,4})\s*(?:‡πÄ‡∏ß‡∏•‡∏≤\s*(\d{1,2}):(\d{1,2})\s*‡∏ô\.)?"
    m = re.search(pattern_full, text)
    if m:
        try:
            day_str = m.group(1)
            raw_month = normalize_month(m.group(2))
            year_str = m.group(3)
            hour_str = m.group(4)
            minute_str = m.group(5)

            day = int(day_str)
            month = thai_months.get(raw_month)
            if not month:
                return None

            if len(year_str) == 2:
                year_thai = 2500 + int(year_str)
            else:
                year_thai = int(year_str)

            year = year_thai - 543
            hour = int(hour_str) if hour_str else 0
            minute = int(minute_str) if minute_str else 0
            return datetime(year, month, day, hour, minute)
        except:
            return None

    # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏µ
    pattern_no_year = r"(\d{1,2})\s+([‡∏Å-‡∏Æ.]+)"
    m = re.search(pattern_no_year, text)
    if m:
        try:
            day_str = m.group(1)
            raw_month = normalize_month(m.group(2))
            month = thai_months.get(raw_month)
            if not month:
                return None
            now = datetime.now()
            year = now.year
            hour = now.hour
            minute = now.minute
            return datetime(year, month, int(day_str), hour, minute)
        except:
            return None

    return None


def parse_thai_datetime(text: str):
    """
    ‡πÄ‡∏•‡∏¥‡∏Å‡πÉ‡∏ä‡πâ parse_relative_time (‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‡∏ß‡∏±‡∏ô) 
    ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ parse_full_thai_datetime ‡πÅ‡∏ó‡∏ô 
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö datetime ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÑ‡∏î‡πâ 
    (‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡∏ï‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á‡πÄ‡∏•‡∏¢‡∏Å‡πá‡πÑ‡∏î‡πâ)
    """
    dt = parse_full_thai_datetime(text)
    return dt

def format_datetime(dt: datetime):
    if not dt:
        return "N/A"
    return dt.strftime("%Y-%m-%d %H:%M:%S")


#################### MAIN SCRIPT ####################

MAX_SCROLLS = 10       # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ scroll ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
SCROLL_STEP_PX = 300
WAIT_SCROLL = 2.5

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏° (post + comment) ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢) ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö 6000
MAX_DATA = 6000

chrome_options = Options()
chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
chrome_options.add_argument('--log-level=3')
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=chrome_options)

try:
    # 1) ‡πÄ‡∏Ç‡πâ‡∏≤ TAG '‡∏´‡∏∏‡πâ‡∏ô'
    driver.get("https://pantip.com/tag/%E0%B8%AB%E0%B8%B8%E0%B9%89%E0%B8%99")
    time.sleep(3)

    print(f"üîΩ Scroll page up to {MAX_SCROLLS} times ...")
    last_height = driver.execute_script("return document.body.scrollHeight")
    scroll_count = 0
    all_post_links = []

    while scroll_count < MAX_SCROLLS:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(WAIT_SCROLL)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            # ‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏Ç‡∏¢‡∏±‡∏ö ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            break
        last_height = new_height
        scroll_count += 1

        # ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å scroll ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏≤
        soup = BeautifulSoup(driver.page_source, "html.parser")
        container = soup.select_one("div.container div.col-lg-8")
        if container:
            posts = container.select("li.pt-list-item")
            for p in posts:
                link_tag = p.select_one("div.pt-list-item__title a")
                if link_tag:
                    href = link_tag.get("href")
                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô full url
                    full_url = href if href.startswith("http") else ("https://pantip.com" + href)
                    if full_url not in all_post_links:
                        all_post_links.append(full_url)

        # ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ‡∏°‡∏≤‡∏Å‡∏û‡∏≠ ‡∏≠‡∏≤‡∏à break ‡πÑ‡∏î‡πâ (‡πÅ‡∏ï‡πà‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏Å‡πá‡∏à‡∏∞‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡πÄ‡∏¢‡∏≠‡∏∞‡πÜ)
        # if len(all_post_links) > ‡∏ö‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç: break

    print(f"‚úÖ ‡πÑ‡∏î‡πâ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(all_post_links)} ‡∏•‡∏¥‡∏á‡∏Å‡πå (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Å‡∏≤‡∏£‡∏±‡∏ô‡∏ï‡∏µ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå 6000)")

    if not all_post_links:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ó‡πá‡∏Å‡∏´‡∏∏‡πâ‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    else:
        # 2) ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏û‡∏™‡∏ï‡πå > ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏´‡∏•‡∏±‡∏Å + ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå
        total_rows = 0
        with open("pantip_data_6000.csv", "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["post_id","type","day","datetime","title","content","author","raw_date"])

            for link in all_post_links:
                if total_rows >= MAX_DATA:
                    # ‡∏Ñ‡∏£‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡πâ‡∏ß
                    break

                # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ
                driver.get(link)
                time.sleep(2)

                # scroll ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                post_scroll_count = 0
                last_h = driver.execute_script("return document.body.scrollHeight")
                while post_scroll_count < 10:
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1.5)
                    new_h = driver.execute_script("return document.body.scrollHeight")
                    if new_h == last_h:
                        break
                    last_h = new_h
                    post_scroll_count += 1

                post_soup = BeautifulSoup(driver.page_source, "html.parser")

                # ---- ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏´‡∏•‡∏±‡∏Å ----
                title_tag = post_soup.select_one("title")
                title = title_tag.get_text(strip=True) if title_tag else "N/A"

                post_dt_div = post_soup.select_one("div.display-post-status-leftside")
                dt_str = post_dt_div.get_text(strip=True) if post_dt_div else ""
                post_dt_obj = parse_thai_datetime(dt_str)
                day_str = post_dt_obj.strftime('%Y-%m-%d') if post_dt_obj else "N/A"
                final_dt_str = format_datetime(post_dt_obj)

                author_tag = post_soup.select_one(".display-post-name")
                author = author_tag.get_text(strip=True) if author_tag else "Unknown"

                writer.writerow([link, "post", day_str, final_dt_str, title, "‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏´‡∏•‡∏±‡∏Å", author, dt_str])
                total_rows += 1
                if total_rows >= MAX_DATA:
                    break

                # ---- ‡∏î‡∏∂‡∏á comment ----
                comment_blocks = post_soup.select("div[id^='comment-']")
                # print(f"üó®Ô∏è {link} => ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå {len(comment_blocks)} ‡∏≠‡∏±‡∏ô")
                for c in comment_blocks:
                    if total_rows >= MAX_DATA:
                        break

                    # ‡πÄ‡∏ß‡∏•‡∏≤
                    time_div = c.select_one("div.display-post-status-leftside")
                    comment_time_str = time_div.get_text(strip=True) if time_div else ""
                    c_dt_obj = parse_thai_datetime(comment_time_str)
                    c_day = c_dt_obj.strftime('%Y-%m-%d') if c_dt_obj else "N/A"
                    c_final_dt = format_datetime(c_dt_obj)

                    content_div = c.select_one("div.display-post-message")
                    comment_text = content_div.get_text(strip=True) if content_div else "N/A"

                    c_author_tag = c.select_one(".display-post-name")
                    c_author = c_author_tag.get_text(strip=True) if c_author_tag else "Unknown"

                    writer.writerow([link, "comment", c_day, c_final_dt, title, comment_text, c_author, comment_time_str])
                    total_rows += 1

        print(f"\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå 'pantip_data_6000.csv' ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_rows} ‡πÅ‡∏ñ‡∏ß")
finally:
    driver.quit()
    print("‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
