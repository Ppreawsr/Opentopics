import csv
import re
import time
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# --------------------------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô parse ‡πÑ‡∏ó‡∏¢ datetime (2 ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö)
# 1) relative time ‡πÄ‡∏ä‡πà‡∏ô "20 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß"
# 2) full thai datetime ‡πÄ‡∏ä‡πà‡∏ô "21 ‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå 2568 ‡πÄ‡∏ß‡∏•‡∏≤ 05:46 ‡∏ô."
# --------------------------------------------------
def parse_thai_datetime(text: str):
    text = text.strip()
    dt = parse_relative_time(text)
    if dt:
        return dt
    dt = parse_full_thai_datetime(text)
    if dt:
        return dt
    return None

def parse_relative_time(text: str):
    text = text.strip()
    unit_map = {
        "‡∏ô‡∏≤‡∏ó‡∏µ": "minutes",
        "‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á": "hours",
        "‡∏ß‡∏±‡∏ô": "days"
    }
    pattern = r"(\d+)\s*(‡∏ô‡∏≤‡∏ó‡∏µ|‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á|‡∏ß‡∏±‡∏ô)(‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß|‡∏Å‡πà‡∏≠‡∏ô)?"
    m = re.search(pattern, text)
    if not m:
        return None
    number_str = m.group(1)
    unit_thai = m.group(2)
    try:
        amount = int(number_str)
        if amount > 999999:
            return None
    except:
        return None

    now = datetime.now()
    if unit_thai not in unit_map:
        return None

    if unit_map[unit_thai] == "minutes":
        dt = now - timedelta(minutes=amount)
    elif unit_map[unit_thai] == "hours":
        dt = now - timedelta(hours=amount)
    elif unit_map[unit_thai] == "days":
        dt = now - timedelta(days=amount)
    else:
        return None
    return dt

def parse_full_thai_datetime(text: str):
    text = text.strip()
    thai_months = {
        "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°": 1,
        "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå": 2,
        "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°": 3,
        "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô": 4,
        "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°": 5,
        "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô": 6,
        "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°": 7,
        "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°": 8,
        "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô": 9,
        "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°": 10,
        "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô": 11,
        "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°": 12
    }
    pattern = r"(\d{1,2})\s+([‡∏Å-‡∏Æ]+)\s+(\d{4})\s*‡πÄ‡∏ß‡∏•‡∏≤\s*(\d{1,2}):(\d{1,2})\s*‡∏ô\."
    m = re.search(pattern, text)
    if not m:
        return None
    day_str = m.group(1)
    month_thai = m.group(2)
    year_thai_str = m.group(3)
    hour_str = m.group(4)
    minute_str = m.group(5)
    try:
        day = int(day_str)
        year_thai = int(year_thai_str)
        hour = int(hour_str)
        minute = int(minute_str)
    except:
        return None

    if month_thai not in thai_months:
        return None

    month = thai_months[month_thai]
    year = year_thai - 543  # ‡πÅ‡∏õ‡∏•‡∏á ‡∏û.‡∏®. -> ‡∏Ñ.‡∏®.

    try:
        dt = datetime(year, month, day, hour, minute)
    except:
        return None
    return dt

def format_datetime(dt: datetime):
    if not dt:
        return "N/A"
    return dt.strftime("%Y-%m-%d %H:%M:%S")


# --------------------------------------------------
# ‡πÇ‡∏Ñ‡πâ‡∏î‡∏´‡∏•‡∏±‡∏Å: Infinite Scroll ‡∏´‡∏ô‡πâ‡∏≤ tag "‡∏´‡∏∏‡πâ‡∏ô", ‡∏à‡∏ô‡πÑ‡∏î‡πâ MAX_POSTS
# ‡πÅ‡∏¢‡∏Å (post/comment) ‡∏•‡∏á CSV, ‡πÉ‡∏™‡πà‡∏≠‡∏¥‡πÇ‡∏°‡∏à‡∏¥
# --------------------------------------------------
MAX_POSTS = 80  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ 
## ‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤‡∏à‡∏≥‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô
    
SCROLL_PAUSE = 3  # ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏´‡∏•‡∏±‡∏á scroll
MAX_SCROLL_NO_CHANGE = 5  # ‡∏´‡∏≤‡∏Å scroll n ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÄ‡∏û‡∏¥‡πà‡∏° -> ‡∏´‡∏¢‡∏∏‡∏î

service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)

try:
    # 1) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà tag "‡∏´‡∏∏‡πâ‡∏ô"
    start_url = "https://pantip.com/tag/‡∏´‡∏∏‡πâ‡∏ô"
    driver.get(start_url)
    time.sleep(5)

    all_post_links = []
    old_len = 0
    scroll_no_change = 0

    # 2) ‡∏ß‡∏ô infinite scroll
    while True:
        print("üîé Scroll ‡∏´‡∏ô‡πâ‡∏≤ tag '‡∏´‡∏∏‡πâ‡∏ô' ...")
        soup = BeautifulSoup(driver.page_source, "html.parser")

        # ‡∏´‡∏≤‡πÇ‡∏û‡∏™‡∏ï‡πå
        container = soup.select_one("#__next > div > div > div > div.container > div:nth-child(6) > div.col-lg-8")
        if not container:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö container")
            break

        posts = container.select("li.pt-list-item")
        for p in posts:
            link_tag = p.select_one("div.pt-list-item__title a")
            if link_tag:
                href = link_tag.get("href")
                if href not in all_post_links:
                    all_post_links.append(href)

        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏ö‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
        if len(all_post_links) >= MAX_POSTS:
            break

        # scroll ‡∏•‡∏á‡∏™‡∏∏‡∏î
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_PAUSE)

        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≥‡∏ô‡∏ß‡∏ô link ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏° -> scroll_no_change++
        new_len = len(all_post_links)
        if new_len == old_len:
            scroll_no_change += 1
            print(f"‚ú® ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÉ‡∏´‡∏°‡πà (scroll_no_change={scroll_no_change})")
            if scroll_no_change >= MAX_SCROLL_NO_CHANGE:
                print("‚ùå ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞ scroll ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°")
                break
        else:
            scroll_no_change = 0
        old_len = new_len

    # ‡∏ï‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ï‡∏≤‡∏° MAX_POSTS
    all_post_links = all_post_links[:MAX_POSTS]
    print(f"‚ú® ‡∏£‡∏ß‡∏°‡πÑ‡∏î‡πâ {len(all_post_links)} ‡πÇ‡∏û‡∏™‡∏ï‡πå")

    # 3) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå
    with open("pantip_data_hun.csv", "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["type", "title", "datetime", "content"])

        for i, link in enumerate(all_post_links, start=1):
            full_url = link if link.startswith("http") else ("https://pantip.com" + link)
            print(f"\n‚öôÔ∏è [{i}/{len(all_post_links)}] ‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏û‡∏™‡∏ï‡πå: {full_url}")
            driver.get(full_url)
            time.sleep(3)

            post_soup = BeautifulSoup(driver.page_source, "html.parser")

            # ‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ
            title_tag = post_soup.select_one("title")
            title = title_tag.get_text(strip=True) if title_tag else "N/A"

            # ‡∏ß‡∏±‡∏ô-‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏û‡∏™‡∏ï‡πå
            post_dt_div = post_soup.select_one("div.display-post-status-leftside")
            dt_str = post_dt_div.get_text(strip=True) if post_dt_div else ""
            post_dt_obj = parse_thai_datetime(dt_str)
            final_dt_str = format_datetime(post_dt_obj)

            # ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÇ‡∏û‡∏™‡∏ï‡πå
            post_content_div = post_soup.select_one("div.display-post-story")
            post_content = post_content_div.get_text(separator=" ", strip=True) if post_content_div else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÇ‡∏û‡∏™‡∏ï‡πå"

            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å row (type=post)
            writer.writerow(["post", title, final_dt_str, post_content])

            # 4) ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå
            comments = post_soup.select("div.display-post-wrapper.section-comment")
            print(f"üí¨ ‡∏û‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå {len(comments)} ‡∏≠‡∏±‡∏ô")
            for c in comments:
                c_dt_div = c.select_one("div.display-post-status-leftside")
                c_dt_str = c_dt_div.get_text(strip=True) if c_dt_div else ""
                c_dt_obj = parse_thai_datetime(c_dt_str)
                c_dt_final = format_datetime(c_dt_obj)

                c_content_div = c.select_one("div.display-post-story-wrapper.comment-wrapper div.display-post-story")
                c_content = c_content_div.get_text(separator=" ", strip=True) if c_content_div else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå"

                writer.writerow(["comment", title, c_dt_final, c_content])

    print("\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", len(all_post_links), "‡πÇ‡∏û‡∏™‡∏ï‡πå, ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á 'pantip_data_hun.csv'")

finally:
    driver.quit()
    print("‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
